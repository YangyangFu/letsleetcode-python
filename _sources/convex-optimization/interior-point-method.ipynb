{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interior-point Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inequality Constrained Minimization Problems\n",
    "\n",
    "The `interior-point` methods are usually for solving convex optimization problem that include inequality constraints:\n",
    "\n",
    "\\begin{align}\n",
    "    \\min & f_0(x) \\\\\n",
    "    \\text{s.t.} & f_i(x) \\le 0, i = 1, ..., m \\\\\n",
    "         & Ax = b\n",
    "\\end{align}\n",
    "where $f_0, f_i$ are convex and twice continuously differentiable.\n",
    "\n",
    "If the problem is strictly feasible, based on Slater's constraint qualification, there exist dual optimal $\\lambda^*, \\mu^*$, which together with $x^*$ statisfy the KKT conditions:\n",
    "\n",
    "\\begin{gather*}\n",
    "Ax^* = b\\\\\n",
    "f_i(x^*) \\le 0\\\\\n",
    "\\lambda^* \\ge 0 \\\\\n",
    "\\nabla f_0(x^*) + \\sum_{i=1}^{m} \\lambda_i \\nabla f_i(x^*) + A^Tv^* = 0 \\\\\n",
    "\\lambda^* f_i(x^*) = 0, i = 1, ..., m\\\\\n",
    "\\end{gather*}\n",
    "\n",
    "Solving the orginal optimizaiton problem is equvelant to solving its KKT conditions. \n",
    "`Interior-point` method applies `Newton's method` to solve the modified version of the KKT conditions or a sequence of equality constrained problems transformed from the origin inequality constrained problem.\n",
    "\n",
    "Two types of methods can be used: `Primal-dual interior-point` or `Barrier method`.\n",
    "\n",
    "# Barrier Fucntion\n",
    "A straight-forward way to solve the orignal problem is to approxmimately formulate the inequality constrained problem as an equality constrained problem to which `Newton's method` can be applied directly.\n",
    "The original problem can be rewritten as:\n",
    "\n",
    "\\begin{gather*}\n",
    "\\min & f_0(x) + \\sum_{i=1}^m I_{-}(f_i(x))\\\\\n",
    "\\text{s.t.} & Ax = b\\\\\n",
    "\\end{gather*}\n",
    "\n",
    "where $I_{-}$ is the indicator method for the nonpositive reals,\n",
    "\n",
    "\\begin{equation*}\n",
    "I_{-}(u) = \\begin{cases}\n",
    "            0, & u \\le 0\\\\\n",
    "            \\infinity, & u \\gt 0\n",
    "            \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "## Logarithmic Barrier Function\n",
    "The basic idea of the barrier method is to approximate the indicator function by the logorithmic function:\n",
    "\n",
    "$$\n",
    "    \\hat I_{-}(u) = -(1/t) log(-u)\n",
    "$$\n",
    "\n",
    "where $t>0$ is a parameter that sets the accuracy of the approximation. The $\\hat I_{-}$ is convex and nondecreasing, and differentiable unlike $I_{-}$. Therefore the following approximation holds:\n",
    "\n",
    "\\begin{gather*}\n",
    "\\min & f_0(x) + \\sum_{i=1}^m -(1/t)\\log(-f_i(x))\\\\\n",
    "\\text{s.t.} & Ax = b\\\\\n",
    "\\end{gather*}\n",
    "\n",
    "The function\n",
    "\n",
    "$$\n",
    "\\phi(x) = -\\sum_{i=1}^m \\log(-f_i(x))\n",
    "$$\n",
    "\n",
    "is called the `logarithmic barrier`, whose gradient and Hessian are given by:\n",
    "\n",
    "\\begin{gather*}\n",
    "\\nabla\\phi(x) = \\sum_{i=1}^m \\frac{1}{-f_i(x)} \\nabla f_i(x) \\\\\n",
    "\\nabla^2\\phi(x) = \\sum_{i=1}^m \\frac{1}{f_i^2(x)} \\nabla f_i(x)^2 + \\sum_{i=1}^m \\frac{1}{-f_i(x)} \\nabla^2 f_i(x) \\\\\n",
    "\\end{gather*}\n",
    "\n",
    "## Central Path\n",
    "By arranging `t` we have the following equavelant problem, which has the same minimizers.\n",
    "\\begin{gather*}\n",
    "\\min & tf_0(x) + \\phi(x)\\\\\n",
    "\\text{s.t.} & Ax = b\\\\\n",
    "\\end{gather*}\n",
    "\n",
    "If the problem has a unique solution for each $t>0$, then the solution is associated with the choice of `t`, which can be denoted by $x^*(t)$. \n",
    "$x^*(t)$ is called the `central points`, which characterize a central path.\n",
    "\n",
    "\n",
    "## Modified KKT Conditions\n",
    "The moodified KKT conditions for the original problem with the barrier function approximation are as follows, which is also called `centrality conditions` in this background:\n",
    "\n",
    "\\begin{gather*}\n",
    "Ax^* = b\\\\\n",
    "f_i(x^*) \\le 0\\\\\n",
    "\\lambda^* \\ge 0 \\\\\n",
    "\\nabla f_0(x^*) + \\sum_{i=1}^{m} \\lambda_i \\nabla f_i(x^*) + A^Tv^* = 0 \\\\\n",
    "-\\lambda^* f_i(x^*) = 1/t, i = 1, ..., m\\\\\n",
    "\\end{gather*}\n",
    "\n",
    "The difference between the KKT condition and the modifided KKT is that the complementary condition $-\\lambda^* f_i(x^*) = 0$ is replaced by the condition $-\\lambda^* f_i(x^*) = 1/t$.\n",
    "In particular, for large $t, x^*(t)$ and the associated dual point $\\lambda^*(t), \\mu^*(t)$ `almost` satisfy the KKT optimality conditions.\n",
    "\n",
    "\n",
    "# Primal-dual Interior-point Method\n",
    "`Primal-dual` interior-point method solves the modified KKT conditions using `Newton's method` by finding a pair of solutions $(x^*, \\lambda^*, \\nu^*)$.\n",
    "\n",
    "`Newton's method` updates at each iteration the solution by a `Newton step`. \n",
    "\n",
    "We define a residual function from the modified KKT conditions as:\n",
    "\n",
    "\\begin{gather}\n",
    "r_t(x, \\lambda, \\nu) = \\begin{bmatrix} \n",
    "                        \\nabla f_0(x) + Df(x)^T\\lambda + A^T \\nu \\\\\n",
    "                        - diag(\\lambda)f(x) - (1/t)I \\\\\n",
    "                        Ax-b\n",
    "                        \\end{bmatrix}\n",
    "\\end{gather}\n",
    "\n",
    "where \n",
    "\\begin{gather}\n",
    "f(x) = \\begin{bmatrix} f_1(x) \\\\ ... \\\\ f_m(x) \\end{bmatrix}, Df(x) = \\begin{bmatrix} \\nabla f_1(x) \\\\ ... \\\\ \\nabla f_m(x) \\end{bmatrix} \n",
    "\\end{gather}\n",
    "\n",
    "The first element in the the residual function is the `dual residual`, the middle element is `centrality residual`, and the last element is `primal residual`. \n",
    "\n",
    "The `Newton's method` can be used to find $(x^*, \\lambda^*, \\nu^*)$ so that the residual function is 0.\n",
    "\n",
    "The `Newton step` for the residual function can be:\n",
    "\n",
    "$$\n",
    "    -\\frac{r_t}{\\nabla r_t}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
